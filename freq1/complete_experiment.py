#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¢‘ç‡ç‰¹æ€§å®éªŒ - å®Œæ•´å®éªŒä»£ç 

è¯¥è„šæœ¬æ•´åˆäº†ä¸¤ä¸ªå®éªŒæ­¥éª¤ï¼š
1. ç¬¬ä¸€æ­¥ï¼šç¥ç»ç½‘ç»œæ‹Ÿåˆé¢‘ç‡å‡½æ•° (x,y) æ˜ å°„
2. ç¬¬äºŒæ­¥ï¼šç¥ç»ç½‘ç»œç›´æ¥é¢„æµ‹é¢‘åŸŸå‚æ•° {a0, a1, b1, a2, b2, ...}

å¢å¼ºçš„å¯è§†åŒ–åŠŸèƒ½ï¼š
- è®­ç»ƒè¿‡ç¨‹ä¸­è¾“å‡ºä¸æ•°æ®ç‚¹çš„æ¼”åŒ–å¯¹æ¯”
- è¾“å‡ºä¸åŸå‡½æ•°çš„å·®åˆ«å±•ç¤º
- å‚æ•°é¢„æµ‹ç²¾åº¦åˆ†æ
- å‡½æ•°é‡æ„è´¨é‡è¯„ä¼°

"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Optional, Any
import json
from datetime import datetime
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import Config
from data_generator import FrequencyDataGenerator
from model import FrequencyNet, FrequencyTrainer
from parameter_model import ParameterPredictionNet, ParameterTrainer
from utils import setup_logging, save_results, create_directory

class CompleteFrequencyExperiment:
    """
    å®Œæ•´çš„é¢‘ç‡ç‰¹æ€§å®éªŒç±»
    æ•´åˆä¸¤ä¸ªå®éªŒæ­¥éª¤å¹¶æä¾›å¢å¼ºçš„å¯è§†åŒ–åŠŸèƒ½
    """
    
    def __init__(self, config: Config):
        self.config = config
        self.logger = setup_logging('complete_experiment')
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        create_directory(self.config.paths['results'])
        create_directory(self.config.paths['models'])
        create_directory(self.config.paths['plots'])
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.data_generator = FrequencyDataGenerator(config)
        
        # å®éªŒç»“æœå­˜å‚¨
        self.results = {
            'step1_results': {},  # ç¬¬ä¸€æ­¥å®éªŒç»“æœ
            'step2_results': {},  # ç¬¬äºŒæ­¥å®éªŒç»“æœ
            'comparison_metrics': {},  # å¯¹æ¯”æŒ‡æ ‡
            'experiment_config': {
                'step1_config': config.model_params,
                'step2_config': config.freq2_params
            }
        }
        
        # å¯è§†åŒ–å†å²è®°å½•
        self.visualization_history = {
            'step1_training_snapshots': [],
            'step2_training_snapshots': [],
            'evolution_data': []
        }
    
    def generate_experiment_data(self, num_samples: int = 1000) -> Tuple[Dict, Dict]:
        """
        ç”Ÿæˆå®éªŒæ•°æ®
        
        Args:
            num_samples: æ ·æœ¬æ•°é‡
            
        Returns:
            step1_data: ç¬¬ä¸€æ­¥å®éªŒæ•°æ®
            step2_data: ç¬¬äºŒæ­¥å®éªŒæ•°æ®
        """
        self.logger.info(f"ç”Ÿæˆ {num_samples} ä¸ªå®éªŒæ ·æœ¬...")
        
        # ç”Ÿæˆå‚æ•°å’Œå‡½æ•°æ•°æ®
        all_params = []
        step1_X = []
        step1_y = []
        step2_X = []
        step2_y = []
        
        num_components = self.config.freq2_params['num_freq_components']
        num_points = self.config.freq2_params['num_data_points']
        x_range = self.config.freq2_params['x_range']
        noise_level = self.config.freq2_params['data_noise_level']
        
        # ç”Ÿæˆxåæ ‡
        x_coords = np.linspace(x_range[0], x_range[1], num_points)
        
        for i in tqdm(range(num_samples), desc="ç”Ÿæˆæ•°æ®"):
            # ç”Ÿæˆéšæœºå‚æ•°
            params = self._generate_random_parameters(num_components)
            all_params.append(params)
            
            # ç”ŸæˆçœŸå®å‡½æ•°å€¼
            y_true = self.data_generator.generate_frequency_function(x_coords, params)
            
            # æ·»åŠ å™ªå£°
            y_noisy = y_true + np.random.normal(0, noise_level, len(y_true))
            
            # ç¬¬ä¸€æ­¥æ•°æ®ï¼š(x, y) æ˜ å°„
            for j in range(len(x_coords)):
                step1_X.append([x_coords[j]])
                step1_y.append([y_noisy[j]])
            
            # ç¬¬äºŒæ­¥æ•°æ®ï¼šæ•°æ®ç‚¹ -> å‚æ•°
            xy_data = np.concatenate([x_coords, y_noisy])
            param_array = self._params_dict_to_array(params, num_components)
            
            step2_X.append(xy_data)
            step2_y.append(param_array)
        
        step1_data = {
            'X': np.array(step1_X),
            'y': np.array(step1_y),
            'x_coords': x_coords,
            'original_functions': all_params
        }
        
        step2_data = {
            'X': np.array(step2_X),
            'y': np.array(step2_y),
            'x_coords': x_coords,
            'original_params': all_params
        }
        
        self.logger.info(f"æ•°æ®ç”Ÿæˆå®Œæˆ: Step1 X.shape={step1_data['X'].shape}, Step2 X.shape={step2_data['X'].shape}")
        return step1_data, step2_data
    
    def run_step1_experiment(self, step1_data: Dict) -> Dict:
        """
        è¿è¡Œç¬¬ä¸€æ­¥å®éªŒï¼šå‡½æ•°æ‹Ÿåˆ
        
        Args:
            step1_data: ç¬¬ä¸€æ­¥å®éªŒæ•°æ®
            
        Returns:
            ç¬¬ä¸€æ­¥å®éªŒç»“æœ
        """
        self.logger.info("å¼€å§‹ç¬¬ä¸€æ­¥å®éªŒï¼šå‡½æ•°æ‹Ÿåˆ...")
        
        # åˆ’åˆ†æ•°æ®é›†
        X, y = step1_data['X'], step1_data['y']
        split_idx = int(0.8 * len(X))
        
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        # åˆ›å»ºæ¨¡å‹
        model = FrequencyNet(
            input_size=self.config.model_params['input_size'],
            hidden_size=self.config.model_params['hidden_size'],
            output_size=self.config.model_params['output_size']
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = FrequencyTrainer(model, self.config)
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆå¸¦å¯è§†åŒ–å›è°ƒï¼‰
        history = trainer.train(
            X_train, y_train, X_test, y_test,
            visualization_callback=self._step1_visualization_callback
        )
        
        # è¯„ä¼°æ¨¡å‹
        test_loss = trainer.evaluate(X_test, y_test)
        
        # ç”Ÿæˆé¢„æµ‹
        predictions = trainer.predict(X_test)
        
        step1_results = {
            'model': model,
            'trainer': trainer,
            'history': history,
            'test_loss': test_loss,
            'predictions': predictions,
            'test_data': {'X': X_test, 'y': y_test}
        }
        
        self.results['step1_results'] = step1_results
        self.logger.info(f"ç¬¬ä¸€æ­¥å®éªŒå®Œæˆï¼Œæµ‹è¯•æŸå¤±: {test_loss:.6f}")
        return step1_results
    
    def run_step2_experiment(self, step2_data: Dict) -> Dict:
        """
        è¿è¡Œç¬¬äºŒæ­¥å®éªŒï¼šå‚æ•°é¢„æµ‹
        
        Args:
            step2_data: ç¬¬äºŒæ­¥å®éªŒæ•°æ®
            
        Returns:
            ç¬¬äºŒæ­¥å®éªŒç»“æœ
        """
        self.logger.info("å¼€å§‹ç¬¬äºŒæ­¥å®éªŒï¼šå‚æ•°é¢„æµ‹...")
        
        # åˆ’åˆ†æ•°æ®é›†
        X, y = step2_data['X'], step2_data['y']
        split_idx = int(0.8 * len(X))
        val_split_idx = int(0.6 * len(X))
        
        X_train = X[val_split_idx:split_idx]
        y_train = y[val_split_idx:split_idx]
        X_val = X[:val_split_idx]
        y_val = y[:val_split_idx]
        X_test = X[split_idx:]
        y_test = y[split_idx:]
        
        # åˆ›å»ºæ¨¡å‹
        input_size = self.config.freq2_params['input_size']
        hidden_dims = self.config.freq2_params['hidden_dims']
        num_components = self.config.freq2_params['num_freq_components']
        output_size = 1 + 2 * num_components
        dropout_rate = self.config.freq2_params['dropout_rate']
        
        model = ParameterPredictionNet(
            input_size=input_size,
            hidden_dims=hidden_dims,
            output_size=output_size,
            dropout_rate=dropout_rate
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = ParameterTrainer(model, self.config)
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆå¸¦å¯è§†åŒ–å›è°ƒï¼‰
        history = trainer.train(
            X_train, y_train, X_val, y_val,
            visualization_callback=self._step2_visualization_callback
        )
        
        # è¯„ä¼°æ¨¡å‹
        metrics = trainer.evaluate(X_test, y_test)
        
        # ç”Ÿæˆé¢„æµ‹æ ·ä¾‹
        predictions = []
        for i in range(min(10, len(X_test))):
            pred_params = model.predict_parameters(X_test[i:i+1])[0]
            true_params = step2_data['original_params'][split_idx + i]
            
            predictions.append({
                'predicted_params': self._array_to_params_dict(pred_params, num_components),
                'true_params': true_params,
                'input_data': X_test[i]
            })
        
        step2_results = {
            'model': model,
            'trainer': trainer,
            'history': history,
            'metrics': metrics,
            'predictions': predictions,
            'test_data': {'X': X_test, 'y': y_test, 'original_params': step2_data['original_params'][split_idx:]}
        }
        
        self.results['step2_results'] = step2_results
        self.logger.info(f"ç¬¬äºŒæ­¥å®éªŒå®Œæˆï¼Œæµ‹è¯•æŒ‡æ ‡: {metrics}")
        return step2_results
    
    def _step1_visualization_callback(self, epoch: int, model: Any, train_loss: float, val_loss: float):
        """
        ç¬¬ä¸€æ­¥å®éªŒçš„å¯è§†åŒ–å›è°ƒå‡½æ•°
        """
        # æ¯10ä¸ªepochè®°å½•ä¸€æ¬¡è®­ç»ƒå¿«ç…§
        if epoch % 10 == 0:
            snapshot = {
                'epoch': epoch,
                'train_loss': train_loss,
                'val_loss': val_loss,
                'timestamp': datetime.now()
            }
            self.visualization_history['step1_training_snapshots'].append(snapshot)
    
    def _step2_visualization_callback(self, epoch: int, model: Any, train_loss: float, val_loss: float):
        """
        ç¬¬äºŒæ­¥å®éªŒçš„å¯è§†åŒ–å›è°ƒå‡½æ•°
        """
        # æ¯20ä¸ªepochè®°å½•ä¸€æ¬¡è®­ç»ƒå¿«ç…§
        if epoch % 20 == 0:
            snapshot = {
                'epoch': epoch,
                'train_loss': train_loss,
                'val_loss': val_loss,
                'timestamp': datetime.now()
            }
            self.visualization_history['step2_training_snapshots'].append(snapshot)
    
    def create_enhanced_visualizations(self, step1_data: Dict, step2_data: Dict):
        """
        åˆ›å»ºå¢å¼ºçš„å¯è§†åŒ–å›¾è¡¨
        
        Args:
            step1_data: ç¬¬ä¸€æ­¥å®éªŒæ•°æ®
            step2_data: ç¬¬äºŒæ­¥å®éªŒæ•°æ®
        """
        self.logger.info("ç”Ÿæˆå¢å¼ºå¯è§†åŒ–å›¾è¡¨...")
        
        # è®¾ç½®ç»˜å›¾æ ·å¼
        plt.style.use(self.config.visualization_params['style'])
        sns.set_palette(self.config.visualization_params['color_palette'])
        
        # 1. è®­ç»ƒæ¼”åŒ–å¯¹æ¯”å›¾
        self._plot_training_evolution()
        
        # 2. å‡½æ•°æ‹Ÿåˆè´¨é‡å¯¹æ¯”
        self._plot_function_fitting_comparison(step1_data)
        
        # 3. å‚æ•°é¢„æµ‹ç²¾åº¦åˆ†æ
        self._plot_parameter_prediction_analysis(step2_data)
        
        # 4. åŸå‡½æ•°vsé¢„æµ‹å‡½æ•°å¯¹æ¯”
        self._plot_original_vs_predicted_functions(step2_data)
        
        # 5. ç»¼åˆæ€§èƒ½å¯¹æ¯”
        self._plot_comprehensive_performance_comparison()
        
        self.logger.info("å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆ")
    
    def _plot_training_evolution(self):
        """
        ç»˜åˆ¶è®­ç»ƒæ¼”åŒ–è¿‡ç¨‹
        """
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('è®­ç»ƒæ¼”åŒ–è¿‡ç¨‹å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        # ç¬¬ä¸€æ­¥è®­ç»ƒå†å²
        if 'step1_results' in self.results and 'history' in self.results['step1_results']:
            history1 = self.results['step1_results']['history']
            axes[0, 0].plot(history1['train_loss'], label='è®­ç»ƒæŸå¤±', alpha=0.8, linewidth=2)
            axes[0, 0].plot(history1['val_loss'], label='éªŒè¯æŸå¤±', alpha=0.8, linewidth=2)
            axes[0, 0].set_title('ç¬¬ä¸€æ­¥ï¼šå‡½æ•°æ‹Ÿåˆè®­ç»ƒå†å²', fontweight='bold')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            axes[0, 0].set_yscale('log')
        
        # ç¬¬äºŒæ­¥è®­ç»ƒå†å²
        if 'step2_results' in self.results and 'history' in self.results['step2_results']:
            history2 = self.results['step2_results']['history']
            axes[0, 1].plot(history2['train_loss'], label='è®­ç»ƒæŸå¤±', alpha=0.8, linewidth=2)
            if 'val_loss' in history2:
                axes[0, 1].plot(history2['val_loss'], label='éªŒè¯æŸå¤±', alpha=0.8, linewidth=2)
            axes[0, 1].set_title('ç¬¬äºŒæ­¥ï¼šå‚æ•°é¢„æµ‹è®­ç»ƒå†å²', fontweight='bold')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('Loss')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
            axes[0, 1].set_yscale('log')
        
        # è®­ç»ƒå¿«ç…§å¯¹æ¯”
        if self.visualization_history['step1_training_snapshots']:
            snapshots = self.visualization_history['step1_training_snapshots']
            epochs = [s['epoch'] for s in snapshots]
            train_losses = [s['train_loss'] for s in snapshots]
            val_losses = [s['val_loss'] for s in snapshots]
            
            axes[1, 0].plot(epochs, train_losses, 'o-', label='è®­ç»ƒæŸå¤±å¿«ç…§', alpha=0.8, markersize=6)
            axes[1, 0].plot(epochs, val_losses, 's-', label='éªŒè¯æŸå¤±å¿«ç…§', alpha=0.8, markersize=6)
            axes[1, 0].set_title('ç¬¬ä¸€æ­¥è®­ç»ƒå¿«ç…§', fontweight='bold')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Loss')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
        
        if self.visualization_history['step2_training_snapshots']:
            snapshots = self.visualization_history['step2_training_snapshots']
            epochs = [s['epoch'] for s in snapshots]
            train_losses = [s['train_loss'] for s in snapshots]
            val_losses = [s['val_loss'] for s in snapshots]
            
            axes[1, 1].plot(epochs, train_losses, 'o-', label='è®­ç»ƒæŸå¤±å¿«ç…§', alpha=0.8, markersize=6)
            axes[1, 1].plot(epochs, val_losses, 's-', label='éªŒè¯æŸå¤±å¿«ç…§', alpha=0.8, markersize=6)
            axes[1, 1].set_title('ç¬¬äºŒæ­¥è®­ç»ƒå¿«ç…§', fontweight='bold')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Loss')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.config.paths['plots'], 'training_evolution.png'),
                   dpi=self.config.visualization_params['dpi'], bbox_inches='tight')
        plt.show()
    
    def _plot_function_fitting_comparison(self, step1_data: Dict):
        """
        ç»˜åˆ¶å‡½æ•°æ‹Ÿåˆè´¨é‡å¯¹æ¯”
        """
        if 'step1_results' not in self.results:
            return
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('ç¬¬ä¸€æ­¥ï¼šå‡½æ•°æ‹Ÿåˆè´¨é‡å¯¹æ¯”ï¼ˆè¾“å‡º vs æ•°æ®ç‚¹ vs åŸå‡½æ•°ï¼‰', fontsize=16, fontweight='bold')
        
        axes = axes.flatten()
        
        step1_results = self.results['step1_results']
        model = step1_results['model']
        x_coords = step1_data['x_coords']
        original_functions = step1_data['original_functions']
        
        # é€‰æ‹©6ä¸ªæ ·ä¾‹è¿›è¡Œå¯¹æ¯”
        num_examples = min(6, len(original_functions))
        selected_indices = np.random.choice(len(original_functions), num_examples, replace=False)
        
        for i, func_idx in enumerate(selected_indices):
            # è·å–åŸå‡½æ•°å‚æ•°
            original_params = original_functions[func_idx]
            
            # ç”ŸæˆåŸå‡½æ•°
            y_original = self.data_generator.generate_frequency_function(x_coords, original_params)
            
            # ç”Ÿæˆå¸¦å™ªå£°çš„æ•°æ®ç‚¹
            noise_level = self.config.freq2_params['data_noise_level']
            y_noisy = y_original + np.random.normal(0, noise_level, len(y_original))
            
            # æ¨¡å‹é¢„æµ‹
            X_pred = np.array([[x] for x in x_coords])
            y_pred = model.predict(X_pred).flatten()
            
            # ç»˜åˆ¶å¯¹æ¯”
            axes[i].plot(x_coords, y_original, 'b-', label='åŸå‡½æ•°', linewidth=2.5, alpha=0.9)
            axes[i].plot(x_coords, y_pred, 'r--', label='æ¨¡å‹è¾“å‡º', linewidth=2.5, alpha=0.9)
            axes[i].scatter(x_coords, y_noisy, c='green', s=25, alpha=0.7, label='æ•°æ®ç‚¹', zorder=5)
            
            # è®¡ç®—è¯¯å·®
            mse_vs_original = np.mean((y_pred - y_original) ** 2)
            mse_vs_data = np.mean((y_pred - y_noisy) ** 2)
            
            axes[i].set_title(f'æ ·ä¾‹ {i+1}\nMSE(vsåŸå‡½æ•°): {mse_vs_original:.4f}\nMSE(vsæ•°æ®): {mse_vs_data:.4f}', 
                            fontsize=10, fontweight='bold')
            axes[i].set_xlabel('x')
            axes[i].set_ylabel('f(x)')
            axes[i].legend(fontsize=9)
            axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.config.paths['plots'], 'function_fitting_comparison.png'),
                   dpi=self.config.visualization_params['dpi'], bbox_inches='tight')
        plt.show()
    
    def _plot_parameter_prediction_analysis(self, step2_data: Dict):
        """
        ç»˜åˆ¶å‚æ•°é¢„æµ‹ç²¾åº¦åˆ†æ
        """
        if 'step2_results' not in self.results:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('ç¬¬äºŒæ­¥ï¼šå‚æ•°é¢„æµ‹ç²¾åº¦åˆ†æ', fontsize=16, fontweight='bold')
        
        predictions = self.results['step2_results']['predictions']
        
        # æå–å‚æ•°å¯¹æ¯”æ•°æ®
        param_names = ['a0', 'a1', 'b1', 'a2', 'b2', 'a3', 'b3']
        true_values = {name: [] for name in param_names}
        pred_values = {name: [] for name in param_names}
        
        for pred in predictions:
            true_params = pred['true_params']
            pred_params = pred['predicted_params']
            
            for name in param_names:
                if name in true_params and name in pred_params:
                    true_values[name].append(true_params[name])
                    pred_values[name].append(pred_params[name])
        
        # å‚æ•°æ•£ç‚¹å›¾å¯¹æ¯”
        for i, param_name in enumerate(['a0', 'a1', 'b1', 'a2']):
            if len(true_values[param_name]) > 0:
                ax = axes[i//2, i%2]
                
                true_vals = np.array(true_values[param_name])
                pred_vals = np.array(pred_values[param_name])
                
                # æ•£ç‚¹å›¾
                ax.scatter(true_vals, pred_vals, alpha=0.7, s=50)
                
                # ç†æƒ³çº¿
                min_val = min(np.min(true_vals), np.min(pred_vals))
                max_val = max(np.max(true_vals), np.max(pred_vals))
                ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=2)
                
                # è®¡ç®—ç›¸å…³ç³»æ•°
                correlation = np.corrcoef(true_vals, pred_vals)[0, 1]
                mse = np.mean((true_vals - pred_vals) ** 2)
                
                ax.set_title(f'å‚æ•° {param_name}\nç›¸å…³ç³»æ•°: {correlation:.3f}, MSE: {mse:.4f}', 
                           fontweight='bold')
                ax.set_xlabel(f'çœŸå® {param_name}')
                ax.set_ylabel(f'é¢„æµ‹ {param_name}')
                ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.config.paths['plots'], 'parameter_prediction_analysis.png'),
                   dpi=self.config.visualization_params['dpi'], bbox_inches='tight')
        plt.show()
    
    def _plot_original_vs_predicted_functions(self, step2_data: Dict):
        """
        ç»˜åˆ¶åŸå‡½æ•°vsé¢„æµ‹å‡½æ•°å¯¹æ¯”
        """
        if 'step2_results' not in self.results:
            return
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('ç¬¬äºŒæ­¥ï¼šåŸå‡½æ•° vs é¢„æµ‹å‡½æ•°å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        axes = axes.flatten()
        predictions = self.results['step2_results']['predictions']
        x_coords = step2_data['x_coords']
        num_points = len(x_coords)
        
        for i, pred in enumerate(predictions[:6]):
            true_params = pred['true_params']
            pred_params = pred['predicted_params']
            input_data = pred['input_data']
            
            # æå–è¾“å…¥æ•°æ®ç‚¹
            x_input = input_data[:num_points]
            y_input = input_data[num_points:]
            
            # ç”Ÿæˆå‡½æ•°
            y_true = self.data_generator.generate_frequency_function(x_coords, true_params)
            y_pred = self.data_generator.generate_frequency_function(x_coords, pred_params)
            
            # ç»˜åˆ¶å¯¹æ¯”
            axes[i].plot(x_coords, y_true, 'b-', label='åŸå‡½æ•°', linewidth=2.5, alpha=0.9)
            axes[i].plot(x_coords, y_pred, 'r--', label='é¢„æµ‹å‡½æ•°', linewidth=2.5, alpha=0.9)
            axes[i].scatter(x_input, y_input, c='green', s=25, alpha=0.7, label='è¾“å…¥æ•°æ®ç‚¹', zorder=5)
            
            # è®¡ç®—è¯¯å·®æŒ‡æ ‡
            mse_func = np.mean((y_true - y_pred) ** 2)
            mse_data = np.mean((y_input - y_pred) ** 2)
            correlation = np.corrcoef(y_true, y_pred)[0, 1]
            
            axes[i].set_title(f'æ ·ä¾‹ {i+1}\nMSE(å‡½æ•°): {mse_func:.4f}\nç›¸å…³æ€§: {correlation:.3f}', 
                            fontsize=10, fontweight='bold')
            axes[i].set_xlabel('x')
            axes[i].set_ylabel('f(x)')
            axes[i].legend(fontsize=9)
            axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.config.paths['plots'], 'original_vs_predicted_functions.png'),
                   dpi=self.config.visualization_params['dpi'], bbox_inches='tight')
        plt.show()
    
    def _plot_comprehensive_performance_comparison(self):
        """
        ç»˜åˆ¶ç»¼åˆæ€§èƒ½å¯¹æ¯”
        """
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('ç»¼åˆæ€§èƒ½å¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold')
        
        # æŸå¤±å¯¹æ¯”
        if 'step1_results' in self.results and 'step2_results' in self.results:
            step1_final_loss = self.results['step1_results']['test_loss']
            step2_metrics = self.results['step2_results']['metrics']
            
            methods = ['ç¬¬ä¸€æ­¥\n(å‡½æ•°æ‹Ÿåˆ)', 'ç¬¬äºŒæ­¥\n(å‚æ•°é¢„æµ‹)']
            losses = [step1_final_loss, step2_metrics.get('test_loss', 0)]
            
            axes[0, 0].bar(methods, losses, alpha=0.8, color=['skyblue', 'lightcoral'])
            axes[0, 0].set_title('æœ€ç»ˆæµ‹è¯•æŸå¤±å¯¹æ¯”', fontweight='bold')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].grid(True, alpha=0.3)
        
        # è®­ç»ƒæ—¶é—´å¯¹æ¯”ï¼ˆå¦‚æœæœ‰è®°å½•ï¼‰
        if hasattr(self, 'training_times'):
            axes[0, 1].bar(methods, self.training_times, alpha=0.8, color=['lightgreen', 'orange'])
            axes[0, 1].set_title('è®­ç»ƒæ—¶é—´å¯¹æ¯”', fontweight='bold')
            axes[0, 1].set_ylabel('æ—¶é—´ (ç§’)')
            axes[0, 1].grid(True, alpha=0.3)
        
        # å‚æ•°é¢„æµ‹ç²¾åº¦åˆ†å¸ƒ
        if 'step2_results' in self.results:
            predictions = self.results['step2_results']['predictions']
            param_errors = []
            
            for pred in predictions:
                true_params = pred['true_params']
                pred_params = pred['predicted_params']
                
                for param_name in ['a0', 'a1', 'a2']:
                    if param_name in true_params and param_name in pred_params:
                        error = abs(true_params[param_name] - pred_params[param_name])
                        param_errors.append(error)
            
            if param_errors:
                axes[1, 0].hist(param_errors, bins=20, alpha=0.8, color='lightblue', edgecolor='black')
                axes[1, 0].set_title('å‚æ•°é¢„æµ‹è¯¯å·®åˆ†å¸ƒ', fontweight='bold')
                axes[1, 0].set_xlabel('ç»å¯¹è¯¯å·®')
                axes[1, 0].set_ylabel('é¢‘æ¬¡')
                axes[1, 0].grid(True, alpha=0.3)
        
        # æ¨¡å‹å¤æ‚åº¦å¯¹æ¯”
        if 'step1_results' in self.results and 'step2_results' in self.results:
            step1_params = sum(p.numel() for p in self.results['step1_results']['model'].parameters())
            step2_params = sum(p.numel() for p in self.results['step2_results']['model'].parameters())
            
            axes[1, 1].bar(['ç¬¬ä¸€æ­¥æ¨¡å‹', 'ç¬¬äºŒæ­¥æ¨¡å‹'], [step1_params, step2_params], 
                          alpha=0.8, color=['gold', 'mediumpurple'])
            axes[1, 1].set_title('æ¨¡å‹å‚æ•°æ•°é‡å¯¹æ¯”', fontweight='bold')
            axes[1, 1].set_ylabel('å‚æ•°æ•°é‡')
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.config.paths['plots'], 'comprehensive_performance.png'),
                   dpi=self.config.visualization_params['dpi'], bbox_inches='tight')
        plt.show()
    
    def _generate_random_parameters(self, num_components: int) -> Dict:
        """
        ç”Ÿæˆéšæœºé¢‘åŸŸå‚æ•°
        """
        bounds = self.config.freq2_params['regularization']['parameter_bounds']
        
        params = {
            'a0': np.random.uniform(bounds['a0'][0], bounds['a0'][1])
        }
        
        a_max = bounds['a_max']
        b_range = bounds['b_range']
        
        for i in range(1, num_components + 1):
            params[f'a{i}'] = np.random.uniform(-a_max, a_max)
            params[f'b{i}'] = np.random.uniform(b_range[0], b_range[1])
        
        return params
    
    def _params_dict_to_array(self, params: Dict, num_components: int) -> np.ndarray:
        """
        å°†å‚æ•°å­—å…¸è½¬æ¢ä¸ºæ•°ç»„
        """
        param_array = [params['a0']]
        
        for i in range(1, num_components + 1):
            param_array.extend([params[f'a{i}'], params[f'b{i}']])
        
        return np.array(param_array)
    
    def _array_to_params_dict(self, param_array: np.ndarray, num_components: int) -> Dict:
        """
        å°†å‚æ•°æ•°ç»„è½¬æ¢ä¸ºå­—å…¸
        """
        params = {'a0': param_array[0]}
        
        idx = 1
        for i in range(1, num_components + 1):
            params[f'a{i}'] = param_array[idx]
            params[f'b{i}'] = param_array[idx + 1]
            idx += 2
        
        return params
    
    def save_complete_results(self):
        """
        ä¿å­˜å®Œæ•´å®éªŒç»“æœ
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = os.path.join(self.config.paths['results'], 
                                   f'complete_experiment_results_{timestamp}.json')
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        serializable_results = self._make_json_serializable(self.results)
        
        save_results(serializable_results, results_file)
        self.logger.info(f"å®Œæ•´å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        # ä¿å­˜æ¨¡å‹
        if 'step1_results' in self.results:
            model_file = os.path.join(self.config.paths['models'], 
                                     f'step1_model_{timestamp}.pth')
            self.results['step1_results']['trainer'].save_checkpoint(model_file)
        
        if 'step2_results' in self.results:
            model_file = os.path.join(self.config.paths['models'], 
                                     f'step2_model_{timestamp}.pth')
            self.results['step2_results']['trainer'].save_checkpoint(model_file)
    
    def _make_json_serializable(self, obj):
        """
        å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼
        """
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {key: self._make_json_serializable(value) for key, value in obj.items() 
                   if key not in ['model', 'trainer']}  # æ’é™¤ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        elif isinstance(obj, (np.integer, np.floating)):
            return obj.item()
        elif hasattr(obj, '__dict__'):
            return str(obj)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¡¨ç¤º
        else:
            return obj
    
    def run_complete_experiment(self, num_samples: int = 1000):
        """
        è¿è¡Œå®Œæ•´çš„ä¸¤æ­¥å®éªŒ
        
        Args:
            num_samples: æ ·æœ¬æ•°é‡
        """
        self.logger.info("å¼€å§‹å®Œæ•´çš„é¢‘ç‡ç‰¹æ€§å®éªŒ...")
        
        try:
            # 1. ç”Ÿæˆå®éªŒæ•°æ®
            step1_data, step2_data = self.generate_experiment_data(num_samples)
            
            # 2. è¿è¡Œç¬¬ä¸€æ­¥å®éªŒ
            step1_results = self.run_step1_experiment(step1_data)
            
            # 3. è¿è¡Œç¬¬äºŒæ­¥å®éªŒ
            step2_results = self.run_step2_experiment(step2_data)
            
            # 4. åˆ›å»ºå¢å¼ºå¯è§†åŒ–
            self.create_enhanced_visualizations(step1_data, step2_data)
            
            # 5. ä¿å­˜ç»“æœ
            self.save_complete_results()
            
            self.logger.info("å®Œæ•´å®éªŒæˆåŠŸå®Œæˆ!")
            
            # æ‰“å°æ€»ç»“
            self._print_experiment_summary()
            
        except Exception as e:
            self.logger.error(f"å®éªŒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
    
    def _print_experiment_summary(self):
        """
        æ‰“å°å®éªŒæ€»ç»“
        """
        print("\n" + "=" * 80)
        print("é¢‘ç‡ç‰¹æ€§å®éªŒå®Œæ•´æ€»ç»“")
        print("=" * 80)
        
        if 'step1_results' in self.results:
            step1_loss = self.results['step1_results']['test_loss']
            print(f"ç¬¬ä¸€æ­¥å®éªŒï¼ˆå‡½æ•°æ‹Ÿåˆï¼‰:")
            print(f"  - æœ€ç»ˆæµ‹è¯•æŸå¤±: {step1_loss:.6f}")
            print(f"  - æ¨¡å‹ç±»å‹: ä¸¤å±‚å…¨è¿æ¥ç½‘ç»œ")
        
        if 'step2_results' in self.results:
            step2_metrics = self.results['step2_results']['metrics']
            print(f"\nç¬¬äºŒæ­¥å®éªŒï¼ˆå‚æ•°é¢„æµ‹ï¼‰:")
            print(f"  - æµ‹è¯•æŒ‡æ ‡: {step2_metrics}")
            print(f"  - æ¨¡å‹ç±»å‹: å¤šå±‚æ„ŸçŸ¥æœº")
        
        print(f"\nå¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {self.config.paths['plots']}")
        print(f"å®éªŒç»“æœå·²ä¿å­˜åˆ°: {self.config.paths['results']}")
        print(f"æ¨¡å‹æ–‡ä»¶å·²ä¿å­˜åˆ°: {self.config.paths['models']}")
        print("\nå®éªŒå®Œæˆ! ğŸ‰")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("=" * 80)
    print("é¢‘ç‡ç‰¹æ€§å®éªŒ - å®Œæ•´å®éªŒä»£ç ")
    print("æ•´åˆç¬¬ä¸€æ­¥ï¼ˆå‡½æ•°æ‹Ÿåˆï¼‰å’Œç¬¬äºŒæ­¥ï¼ˆå‚æ•°é¢„æµ‹ï¼‰")
    print("=" * 80)
    
    # åˆå§‹åŒ–é…ç½®
    config = Config()
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = CompleteFrequencyExperiment(config)
    
    # è¿è¡Œå®Œæ•´å®éªŒ
    experiment.run_complete_experiment(num_samples=800)
    
    print("\nå®Œæ•´å®éªŒå·²å®Œæˆ! è¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨å’Œç»“æœæ–‡ä»¶ã€‚")

if __name__ == "__main__":
    main()